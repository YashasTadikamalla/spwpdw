{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d8a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45567a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    log_likelihood = -np.log(y_pred[range(m), y_true.argmax(axis=1)])\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6dee681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a neural network class\n",
    "class SimpleNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate):\n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward pass\n",
    "        self.Z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.A1 = sigmoid(self.Z1)\n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = softmax(self.Z2)\n",
    "        return self.A2\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        # Backward pass\n",
    "        m = y.shape[0]\n",
    "        dZ2 = output - y\n",
    "        dW2 = np.dot(self.A1.T, dZ2) / m\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "        dZ1 = np.dot(dZ2, self.W2.T) * sigmoid_derivative(self.A1)\n",
    "        dW1 = np.dot(X.T, dZ1) / m\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "\n",
    "    def train(self, X, y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output)\n",
    "            loss = compute_loss(y, output)\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90d7c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to a flattened array of 784 features\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten the tensor to a 784-dimensional vector\n",
    "])\n",
    "\n",
    "# Download and load the training and test datasets\n",
    "train_dataset = datasets.MNIST(root='dataset', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='dataset', train=False, transform=transform, download=True)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Convert the data into NumPy arrays\n",
    "def load_data(loader):\n",
    "    data, targets = [], []\n",
    "    for images, labels in loader:\n",
    "        data.append(images.numpy())\n",
    "        targets.append(labels.numpy())\n",
    "    data = np.vstack(data)\n",
    "    targets = np.hstack(targets)\n",
    "    return data, targets\n",
    "\n",
    "X_train, y_train = load_data(train_loader)\n",
    "X_test, y_test = load_data(test_loader)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = np.eye(10)[y_train]\n",
    "\n",
    "y_test = np.eye(10)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7013b3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 2.2874\n",
      "Epoch 200/1000, Loss: 2.1702\n",
      "Epoch 300/1000, Loss: 1.7493\n",
      "Epoch 400/1000, Loss: 1.3145\n",
      "Epoch 500/1000, Loss: 1.0437\n",
      "Epoch 600/1000, Loss: 0.8697\n",
      "Epoch 700/1000, Loss: 0.7481\n",
      "Epoch 800/1000, Loss: 0.6604\n",
      "Epoch 900/1000, Loss: 0.5955\n",
      "Epoch 1000/1000, Loss: 0.5461\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training network\n",
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "nn = SimpleNN(input_size, hidden_size, output_size, learning_rate)\n",
    "nn.train(X_train, y_train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cbc2a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 86.23\n",
      "Accuracy on test set: 86.60\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluation\n",
    "def evaluate(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    accuracy = np.mean(predictions == y.argmax(axis=1))\n",
    "    return accuracy\n",
    "\n",
    "train_accuracy = evaluate(nn, X_train, y_train)\n",
    "test_accuracy = evaluate(nn, X_test, y_test)\n",
    "\n",
    "print(f'Accuracy on training set: {train_accuracy * 100:.2f}')\n",
    "print(f'Accuracy on test set: {test_accuracy * 100:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
